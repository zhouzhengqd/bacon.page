<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
    background-color: #d1e7ff; /* 背景色变化 */
    border-radius: 8px;
    transition: background-color 0.3s;
}

	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
	/* 将所有 h2 标签的字体设置为斜体，去掉粗体，并减小标题大小 */
	h2 {
		font-style: italic; /* 设置斜体 */
		font-weight: normal; /* 取消加粗 */
		font-size: 1.2em; /* 减小标题的字体大小 */
	}

	/* 对数学公式进行进一步调整 */
	p {
		font-family: 'Times New Roman', serif; /* 使用经典的 serif 字体，增加数学美感 */
		font-size: 0.9em; /* 减小叙述性文字的大小 */
	}

	/* 给数学公式应用更好的排版 */
	.math {
		font-style: italic; /* 斜体 */
		font-size: 1.1em; /* 稍微增大字体，使得公式更加醒目 */
	}


</style>

<html>
<head>
	<title>BACON: Bayesian Optimal Condensation Framework for Dataset Distillation</title>
	<link rel="icon" href="resources/bacon.png" type="image/x-icon">
	<meta property="og:image" content="resources/bacon.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="BACON: Bayesian Optimal Condensation Framework for Dataset Distillation." />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<hr>
	<br>
	<center>
		<div style="text-align: center; margin-bottom: 10px;">
			<!-- 图片部分，确保居中 -->
			<img class="round" style="width: 180px; display: block; margin: 0 auto 5px auto;" src="./resources/bacon.png" alt="BACON Logo" />
			
			<!-- 标题部分 -->
			<span style="font-size: 36px; font-weight: bold; line-height: 1.2;">
				<span style="font-size: 36px; font-weight: bold; position: relative; color: transparent; display: inline-block; background-color: black; -webkit-background-clip: text; background-image: url('./resources/fire-flames.gif'); background-size: 100% 100%; animation: flameEffect 0.5s infinite linear;">B</span>
				<span style="font-size: 36px; font-weight: bold; position: relative; color: transparent; display: inline-block; background-color: black; -webkit-background-clip: text; background-image: url('./resources/fire-flames.gif'); background-size: 100% 100%; animation: flameEffect 0.5s infinite linear;">A</span>
				<span style="font-size: 36px; font-weight: bold; position: relative; color: transparent; display: inline-block; background-color: black; -webkit-background-clip: text; background-image: url('./resources/fire-flames.gif'); background-size: 100% 100%; animation: flameEffect 0.5s infinite linear;">C</span>
				<span style="font-size: 36px; font-weight: bold; position: relative; color: transparent; display: inline-block; background-color: black; -webkit-background-clip: text; background-image: url('./resources/fire-flames.gif'); background-size: 100% 100%; animation: flameEffect 0.5s infinite linear;">O</span>
				<span style="font-size: 36px; font-weight: bold; position: relative; color: transparent; display: inline-block; background-color: black; -webkit-background-clip: text; background-image: url('./resources/fire-flames.gif'); background-size: 100% 100%; animation: flameEffect 0.5s infinite linear;">N</span>
		
				<!-- 其他文字部分 -->
				<span style="font-size: 36px; font-weight: normal; color: #333;">
					: Bayesian Optimal Condensation Framework for Dataset Distillation
				</span>
			</span>
		</div>
		
		
		<!-- 动画效果 -->
		<style>
			@keyframes flameEffect {
				0% {
					background-position: 0% 0%;
				}
				50% {
					background-position: 100% 100%;
				}
				100% {
					background-position: 0% 0%;
				}
			}
		</style>
		
		
		
		
		
		
		
		
		
		
		
		
		<table align=center width=600px>
			<table align="center" width="100%" style="border-collapse: collapse;">
				<!-- 第一行作者 -->
				<tr>
					<td align="center" width="12%">
						<a href="https://zhouzhengqd.github.io/" style="font-size: 20px; text-decoration: none;">Zheng Zhou<sup>1</sup></a>
					</td>
					<td align="center" width="12%">
						<a href="https://shi.buaa.edu.cn/09698/zh_CN/index.htm" style="font-size: 20px; text-decoration: none;">Hongbo Zhao<sup>1</sup></a>
					</td>
					<td align="center" width="15%" style="white-space: nowrap;">
						<a href="https://sites.google.com/view/guangliangcheng" style="font-size: 20px; text-decoration: none;">Guangliang Cheng<sup>2</sup></a>
					</td>
					<td align="center" width="12%">
						<a href="https://lxtgh.github.io/" style="font-size: 20px; text-decoration: none;">Xiangtai Li<sup>3</sup></a>
					</td>
			
					<td align="center" width="12%">
						<a href="https://scholar.google.com/citations?user=SwGcxzMAAAAJ&hl=en" style="font-size: 20px; text-decoration: none;">Shuchang Lyu<sup>1*</sup></a>
					</td>
					<td align="center" width="12%">
						<a href="https://shi.buaa.edu.cn/fengwenquan/zh_CN/index/132879/list/" style="font-size: 20px; text-decoration: none;">Wenquan Feng<sup>1</sup></a>
					</td>
					<td align="center" width="12%">
						<a href="https://shi.buaa.edu.cn/07297/zh_CN/index.htm" style="font-size: 20px; text-decoration: none;">Qi Zhao<sup>1</sup></a>
					</td>
				</tr>
			
				<!-- 机构信息 -->
				<tr>
					<td colspan="7" align="center" style="font-size: 20px; line-height: 1.6;">
						<sup>1</sup>Beihang University, 
						<sup>2</sup>University of Liverpool, 
						<sup>3</sup>Nanyang Technological University
					</td>
				</tr>				
			</table>
			<!-- 脚注 -->
			<p style="font-size: 18px; text-align: center;">* Corresponding Author</p>
			<table align="center" width="70%" style="border-collapse: separate; margin-top: 20px; border-spacing: 10px;">
				<tr>
					<td style="text-align: center; width: 33%; padding: 15px; background-color: #f0f8ff; border-radius: 8px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">
						<a href='https://arxiv.org/pdf/2406.01112' style="text-decoration: none; color: #000; display: flex; justify-content: center; align-items: center; transition: all 0.3s ease;">
							<img src="https://img.icons8.com/ios/50/000000/paper-plane.png" alt="Paper Icon" style="width: 30px; margin-right: 8px;">
							<span style="font-size: 18px; font-weight: bold;">[Paper]</span>
						</a>
					</td>
					<td style="text-align: center; width: 33%; padding: 15px; background-color: #e0f7fa; border-radius: 8px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">
						<a href='https://github.com/zhouzhengqd/BACON.git' style="text-decoration: none; color: #000; display: flex; justify-content: center; align-items: center; transition: all 0.3s ease;">
							<img src="https://img.icons8.com/ios/50/000000/github.png" alt="GitHub Icon" style="width: 30px; margin-right: 8px;">
							<span style="font-size: 18px; font-weight: bold;">[GitHub]</span>
						</a>
					</td>
					<td style="text-align: center; width: 34%; padding: 15px; background-color: #fff3e6; border-radius: 8px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">
						<a href='https://share.multcloud.link/share/f496af96-494a-4815-a7c9-e93cd95ecdd1' style="text-decoration: none; color: #000; display: flex; justify-content: center; align-items: center; transition: all 0.3s ease;">
							<img src="https://img.icons8.com/ios/50/000000/download.png" alt="Download Icon" style="width: 30px; margin-right: 8px;">
							<span style="font-size: 18px; font-weight: bold;">[Distilled Dataset]</span>
						</a>
					</td>
				</tr>
			</table>
			
			
			
			
			
			
			
		</table>
	</center>


	<hr>

	<table align="center" width="850px">
		<tr>
			<td width="260px">
				<center>
					<figure>
						<img class="round" style="width:800px" src="./resources/overview.png"/>
						<figcaption style="font-size: 16px; text-align: left; color: #555;">
							<strong>Figure 1:</strong> Comparison of our method with previous methods: (a) Existing DD methods typically align gradients and distributions, but lack theoretical guarantees. (b) BACON models DD as a Bayesian optimization problem, generating synthetic images by assessing likelihood and prior probabilities, thereby improving accuracy and reducing training costs. 
						</figcaption>
					</figure>
				</center>
			</td>
		</tr>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				<p style="background-color: #f0f0f0; padding: 15px;">
					<strong>Abstract:</strong> Dataset Distillation (DD) aims to condense large datasets into compact synthetic sets that preserve performance on unseen data, thereby reducing storage and training costs. However, most existing methods emphasize empirical performance without solid theoretical grounding, leaving issues such as optimization inefficiency and the lack of theoretical guarantees against suboptimal solutions unresolved. To bridge this gap, we propose the <u><strong>BA</strong></u>yesian optimal <u><strong>CON</strong></u>densation framework (<u><strong>BACON</strong></u>), the first to incorporate a Bayesian perspective into dataset distillation. BACON offers a principled probabilistic formulation by casting DD as a Bayesian optimization problem, addressing the lack of Bayesian theoretical analysis in prior methods. To characterize the theoretical limit of DD, we derive a numerically tractable lower bound on the expected risk over the joint distribution of latent variables. Under mild assumptions, we obtain an approximate solution for data synthesis, where incorporating prior knowledge improves optimization efficiency through guiding posterior estimation. We evaluate BACON against 18 state-of-the-art methods on four standard image classification datasets under various images-per-class (IPC) settings, where it consistently demonstrates superior performance. For example, under the IPC-10 setting on CIFAR-10, BACON achieves the largest accuracy gain of 17.16\% among all methods, outperforming the second-best approach, IDM, by 3.46\%, while also reducing both synthesis and training costs. These results underscore the theoretical soundness and practical effectiveness of BACON for dataset distillation. Code and distilled datasets are available at <a href="https://github.com/zhouzhengqd/BACON" 
					target="_blank"><u><strong>BACON</strong></u></a>.
				</p>
				
				
			</td>
		</tr>
	</table>
	<br>
	
	<hr>
	
	<center><h1>Background, Motivation, and Contribution</h1></center> <p> <strong>Dataset Distillation (DD)</strong> aims to reduce dataset size while maintaining model performance. Despite significant progress in dataset distillation, most existing methods prioritize empirical performance over theoretical grounding, leading to inefficient optimization and a lack of theoretical guarantees against suboptimal solutions. Fundamentally, DD can be framed as an \textbf{optimization problem over probability distributions}, yet existing approaches lack a principled probabilistic formulation as shown in <strong>Figure 1(a)</strong>. To explore Bayesian principles for dataset distillation, leading to the following key research questions: 
	
	</p> <ul> <li><i>How can dataset distillation be framed within a probabilistic framework?

	</i></li> <li><i>What is the theoretical lower bound for optimal condensation?
		
	</i></li> <li><i>How can Bayesian methods enable efficient and practical data synthesis? </ul> <p></p> 
	
	To address the aforementioned challenges, we propose the <strong>Bayesian Optimal Condensation Framework (BACON)</strong>, the first to apply a Bayesian perspective to dataset distillation. BACON formulates dataset distillation (also referred to as condensation) as a Bayesian optimization problem that minimizes expected risk. A theoretical lower bound is derived over the joint distribution of latent variables, revealing the fundamental limits of optimal condensation. For practical implementation, the risk is approximated under specific assumptions, enabling efficient data synthesis through likelihood estimation and prior knowledge from the original dataset. The BACON method is illustrated in <strong>Figure 1(b)</strong>, along with results on accuracy and training time. BACON is evaluated against 18 state-of-the-art methods on four standard image classification datasets: SVHN, CIFAR-10, CIFAR-100, and TinyImageNet, under varying IPC settings. It consistently outperforms all compared methods, including gradient-based approaches (e.g., DC, DSA, DCC), distribution-based approaches (e.g., IDM, DataDAM, IID), and recent methods such as G-VBSM and Teddy. For example, under the IPC-10 setting on CIFAR-10, BACON achieves the highest accuracy improvement of 17.16%, surpassing the second-best approach, IDM, by 3.46%, while also reducing both synthesis and training costs. These results highlight the theoretical rigor and practical advantages of BACON in dataset distillation.
	Key Benefits of BACON:
	<ul>
		<li><i><strong>First Bayesian DD Framework:</strong> We are the first to introduce a Bayesian framework for dataset distillation, formulating it as a Bayesian optimization problem that minimizes the expected risk. We derive a theoretical lower bound on the expected risk over the joint distribution of latent variables, providing new insights into the fundamental limits of optimal condensation.</i></li>
		<li><i><strong>Efficient Distillation Algorithm:</strong> We propose the BACON framework (Bayesian optimal CONdensation), an efficient method that minimizes the expected risk for dataset distillation. By incorporating key assumptions such as a Gaussian prior and a total variance constraint, BACON derives loss terms to effectively guide the distillation process.</i></li>
		<li><i><strong>Superior Empirical Performance:</strong> Extensive experiments comparing BACON with various dataset distillation methods across multiple image classification datasets demonstrate that BACON consistently outperforms all methods, showcasing superior performance in both accuracy and efficiency.</i></li>
	  </ul>
	<hr>
	<center><h1>Bayesian Optimal Condensation Framework</h1></center> <tr> <td width="260px"> <center> <figure> <img class="round" style="width:800px" src="./resources/method.png"/> <figcaption style="font-size: 16px; text-align: left; color: #555;"> <strong>Figure 2:</strong> Overview of BACON: BACON formulates DD as Bayesian risk minimization over embeddings (*), and derives a tractable lower bound for optimization (I), guided by prior and likelihood from the original data (II). Monte Carlo sampling accelerates optimization (III), and a loss is constructed under two assumptions (IV) to update synthetic data via gradient descent (V). </figcaption> </figure> </center> </td> </tr> <p>As shown in <strong>Figure 2</strong>, BACON uses a Bayesian-based joint probability model to optimize dataset distillation. It derives a condensation risk function to compute the optimal synthetic dataset and applies approximation methods for efficient solution. The Bayesian optimal condensation risk function is defined in <a href="#theorem3.4">Theorem 3.4</a>, and the risk function’s theoretical lower bound is established in <a href="#theorem3.6">Theorem 3.6</a>. Assumptions on <a href="#assumption1">log-likelihood</a> and <a href="#assumption2">prior distribution</a> are introduced to approximate solutions and define the training strategy. BACON represents the first theoretical analysis of optimal condensation via Bayesian principles, providing a strong foundation for improved distillation performance.</p>
		
	  <head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>Math Theorem Example</title>
		<script type="text/javascript" async
		  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
		</script>
	</head>
	<body>
		<h2 id="theorem3.4">Theorem 3.4: The expected risk function in a joint probability distribution can also be calculated as follows:</h2>
		<p class="math">
			\[
			R(\phi_\theta) = 1- \mathbb{E}_{z_{\tilde{x}} \sim p(z_{\tilde{x}})}\left[\int_{\mathcal{B}(z_{\tilde{x}},\epsilon)}p(z_x| z_{\tilde{x}})dz_x\right].
			\]
		</p>
	
		<h2 id="theorem3.6">Theorem 3.6: The optimal embedding feature of synthetic image can be computed as follows:</h2>
		<p class="math">
			\[
			z_{\tilde{x}}^* = \arg\max_{z_{\tilde{x}} \in \mathcal{D}_S} \int_{\mathcal{B}(z_{\tilde{x}}, \epsilon)} \left[\log p(z_{\tilde{x}} | z_x) + \log p(z_x)\right] dz_x.
			\]
		</p>
	
		<h2 id="assumption1">Assumption 1: Likelihood Conforming Gaussian</h2>
		<p>
			To estimate the log-likelihood \( \log p(z_{\tilde{x}} | z_{x_i}) \), we make the assumption that \( p(z_{\tilde{x}} | z_{x_i}) \) conforms to a Gaussian distribution. In this distribution, \( \sigma_x^2 \) represents the variance and \( z_{x_i} \) represents the mean. It is denoted as:
		</p>
		<p class="math">
			\[
			p(z_{\tilde{x}} | z_{x_i}) \sim \mathcal{N}(z_{x_i}, \sigma_{xi}^2 I)
			\]
		</p>
	
		<h2 id="assumption2">Assumption 2: Prior Distribution Approximation with TV Extension</h2>
		<p>
			The Total Variation (TV) and CLIP operation are incorporated as distribution priors to represent \( \log p(z_{x_i}) \). The CLIP operation constrains the probability within the bound of \( [0,1] \). In contrast to their study, we extend the TV from a pixel-wise approach to a distribution-wise approach, which is also referred to as the total variation of probability distribution measures.
		</p>
	</body>


	<hr>

	<center><h1>Results</h1></center>

	<table align=center width=420px>
		<center>
			<tr>
				<td width="260px">
					<center>
						<figure>
							<img class="round" style="width:800px" src="./resources/results_1.png"/>
							<figcaption style="font-size: 16px; text-align: left; color: #555;">
								<strong>Table 1:</strong> Comparison with previous methods: BACON is compared with 18 state-of-the-art methods (4 coreset selection and 14 dataset distillation) across 4 datasets with varying IPC, including pruning-based (Prun.), meta-learning (Meta), gradient-based (Grad.), kernel-based (Kern.), hybrid-based (Hybr.), and distribution-based (Dist.) approaches (abbreviations in the table). ``Ratio(%)'' indicates the proportion of condensed images relative to the full training set, and ``Full Set'' shows accuracy with the original dataset. DD and LD refer to early-stage distillation methods with AlexNet, while others use ConvNet. Best accuracy (%) is in <span style="font-weight: bold; color: #000000;">bold</span>, second-best in <span style="text-decoration: underline; color: #000000;">underlined</span>, and worst in <span style="color: #888888;">gray</span>; improvements over the second-best and worst are shown in <span style="color: #ef5350;">light red</span> and <span style="color: #c62828;">dark red</span>, respectively.
							</figcaption>
						</figure>
					</center>
				</td>
			</tr>
				<tr>
				<td width="260px">
					<center>
						<figure>
							<img class="round" style="width:800px" src="./resources/results_2.png"/>
							<figcaption style="font-size: 16px; text-align: left; color: #555;">
								<strong>Figure 3:</strong> Performance comparison with BACON, IDM, and DM across varying training steps on the CIFAR-10/100 datasets: The blue line with white circles represents our proposed BACON, the orange line with white circles represents IDM, and the green line with white circles represents DM. All synthetic images are generated using the CIFAR-10/100 datasets across training steps from 0 to 20000 with IPC-1, IPC-10, and IPC-50, respectively. 
							</figcaption>
						</figure>
					</center>
				</td>
			</tr>
		</center>
	</table>
	<hr>
	<table align=center width=450px>
		<center><h1>Visulization</h1></center>
		<tr>
			<td><img class="round" style="width:800px" src="./resources/svhn.png"/></td>
		</tr>
		<tr>
			<td><img class="round" style="width:800px" src="./resources/cifar-100.png"/></td>
		</tr>
		<tr>
			<td><img class="round" style="width:800px" src="./resources/visulization.png"/></td>
		</tr>
	</table>
	<br>

	<hr>
	<table align=center width=450px>
		<center><h1>Paper</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">Zheng Zhou, Hongbo Zhao, Guangliang Cheng, Xiangtai Li, Shuchang Lyu, Wenquan Feng, and Qi Zhao<br>
				<b>BACON: Bayesian Optimal Condensation Framework for Dataset Distillation.</b><br>
				In submission, 2024.<br>
				(hosted on <a href="https://arxiv.org/pdf/2406.01112">ArXiv</a>)<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>
	<div style="text-align: center; width: 900px; margin: 0 auto;">
		<h1>Acknowledgements</h1>
		<p>We gratefully acknowledge the contributions of the DC-bench and IDM teams, as our code builds upon their work. You can find their repositories here: 
			<a href="https://github.com/justincui03/dc_benchmark?tab=readme-ov-file" target="_blank">DC-bench</a> and 
			<a href="https://github.com/uitrbn/IDM" target="_blank">IDM</a>.
		</p>
		<p>This template was originally created by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for their <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project. The code can be found <a href="https://github.com/richzhang/webpage-template" target="_blank">here</a>.</p>
	</div>
	

<br>
</body>
</html>

